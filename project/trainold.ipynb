import pandas as pd
import numpy as np
from sklearn import preprocessing
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, f1_score, jaccard_score
import joblib

# Load data
data = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_2.csv")
X = pd.read_csv("https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/datasets/dataset_part_3.csv")
Y = pd.Series(data['Class'].to_numpy())

# Standardize X
transform = preprocessing.StandardScaler()
X = transform.fit(X).transform(X)

# Train/test split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)

# Train multiple models
models = {
    "LogisticRegression": (LogisticRegression(), {"C": [0.01, 0.1, 1], "penalty": ["l2"], "solver": ["lbfgs"]}),
    "SVM": (SVC(), {"kernel": ["linear", "rbf", "poly", "sigmoid"], "C": np.logspace(-3, 3, 5), "gamma": np.logspace(-3, 3, 5)}),
    "DecisionTree": (DecisionTreeClassifier(), {
        "criterion": ["gini", "entropy"],
        "splitter": ["best", "random"],
        "max_depth": [2*n for n in range(1,10)],
        "max_features": ["sqrt"],
        "min_samples_leaf": [1, 2, 4],
        "min_samples_split": [2, 5, 10]
    }),
    "KNN": (KNeighborsClassifier(), {
        "n_neighbors": list(range(1, 11)),
        "algorithm": ["auto", "ball_tree", "kd_tree", "brute"],
        "p": [1, 2]
    }),
}

results = {}
for name, (model, params) in models.items():
    print(f"Training {name}...")
    clf = GridSearchCV(model, params, cv=10)
    clf.fit(X_train, Y_train)
    yhat = clf.predict(X_test)
    results[name] = {
        "best_params": clf.best_params_,
        "test_accuracy": clf.score(X_test, Y_test),
        "f1_score": f1_score(Y_test, yhat),
        "jaccard_score": jaccard_score(Y_test, yhat),
        "model": clf.best_estimator_
    }
    print(f"â†’ {name} done.")

# Save best model (highest accuracy)
best_model_name = max(results, key=lambda k: results[k]["test_accuracy"])
joblib.dump(results[best_model_name]["model"], "model.pkl")
print(f"Best model saved: {best_model_name}")